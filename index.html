<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Late Night Attendance</title>
    <script defer src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
            background-color: #121212;
            color: #ffffff;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            margin: 0;
            text-align: center;
            padding: 20px;
            box-sizing: border-box;
            overflow: hidden; /* Prevent scrolling */
        }
        h1 { margin-bottom: 5px; font-weight: 700; }
        p { color: #aaaaaa; margin-bottom: 30px; margin-top: 0;}
        
        /* Container for Video + AI Canvas */
        #camera-wrapper {
            position: relative;
            width: 100%;
            max-width: 350px;
            aspect-ratio: 3/4;
            background-color: #333;
            border-radius: 20px;
            overflow: hidden;
            box-shadow: 0 4px 15px rgba(0,0,0,0.5);
            display: none; 
        }
        
        video {
            width: 100%;
            height: 100%;
            object-fit: cover;
            position: absolute;
            top: 0;
            left: 0;
        }

        /* The Canvas where AI draws the box */
        canvas {
            position: absolute;
            top: 0;
            left: 0;
        }

        button {
            background-color: #007aff;
            color: white;
            border: none;
            padding: 15px 30px;
            font-size: 18px;
            border-radius: 12px;
            cursor: pointer;
            margin-top: 20px;
            transition: background 0.3s, transform 0.1s;
            width: 100%;
            max-width: 300px;
            font-weight: 600;
        }
        button:disabled { background-color: #444; color: #888; cursor: not-allowed; }
        
        #status { margin-top: 20px; font-size: 16px; min-height: 24px; font-weight: bold;}
        .success { color: #00ff88; }
        .error { color: #ff4444; }
        .info { color: #00aaff; }
        .scanning { color: #ffcc00; animation: blink 1s infinite; }

        @keyframes blink { 50% { opacity: 0.5; } }
        
        #debug-log {
            margin-top: 10px;
            font-size: 10px;
            color: #555;
            font-family: monospace;
        }
    </style>
</head>
<body>

    <h1>Scholar Zolo</h1>
    <p>GFAS (Geo Fenced Attendance System)</p>

    <div id="camera-wrapper">
        <video id="video" autoplay playsinline muted></video>
        </div>

    <div id="controls">
        <button id="start-btn" onclick="initApp()">üìç Verify Location & Scan</button>
    </div>

    <div id="status">Ready to scan...</div>
    <div id="debug-log"></div>

    <script>
        // --- CONFIGURATION ---
        const TEST_MODE = false; // Set to true to skip GPS for testing
        
        // HOSTEL GEOFENCE
        const HOSTEL_POLYGON = [
            { lat: 13.128425, lng: 77.589451 },
            { lat: 13.128249, lng: 77.589476 },
            { lat: 13.128287, lng: 77.588653 },
            { lat: 13.128426, lng: 77.588660 }
        ];

        // --- VARIABLES ---
        const statusEl = document.getElementById('status');
        const debugEl = document.getElementById('debug-log');
        const cameraWrapper = document.getElementById('camera-wrapper');
        const startBtn = document.getElementById('start-btn');
        let videoEl;
        let detectionInterval;
        let faceConfirmedFrames = 0; // How long we've seen a face

        async function initApp() {
            startBtn.disabled = true;
            statusEl.innerText = "Loading AI Models...";
            
            try {
                // 1. Load the AI Model (Tiny Face Detector)
                // We assume the model files are in the same directory as index.html
                await faceapi.nets.tinyFaceDetector.loadFromUri('./'); 
                
                statusEl.innerText = "Checking GPS...";
                checkLocation();
            } catch (err) {
                console.error(err);
                showError("Error loading AI. Did you upload the model files?");
            }
        }

        function checkLocation() {
            if (TEST_MODE) {
                console.log("TEST MODE: Skipping GPS");
                successLocation();
                return;
            }

            if (!navigator.geolocation) {
                showError("Geolocation not supported.");
                return;
            }

            navigator.geolocation.getCurrentPosition(
                (position) => {
                    const userPos = { lat: position.coords.latitude, lng: position.coords.longitude };
                    debugEl.innerText = `Lat: ${userPos.lat.toFixed(5)} Lng: ${userPos.lng.toFixed(5)}`;
                    
                    if (isPointInPolygon(userPos, HOSTEL_POLYGON)) {
                        successLocation();
                    } else {
                        showError("‚ùå You are outside the designated area.");
                        startBtn.disabled = false;
                    }
                },
                (error) => {
                    showError("GPS Error. Allow permissions.");
                    startBtn.disabled = false;
                },
                { enableHighAccuracy: true, timeout: 10000 }
            );
        }

        function successLocation() {
            statusEl.innerText = "‚úÖ Location Verified! Starting Camera...";
            statusEl.className = "success";
            setTimeout(startCamera, 1000);
        }

        async function startCamera() {
            cameraWrapper.style.display = 'block';
            startBtn.style.display = 'none';
            videoEl = document.getElementById('video');

            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' } });
                videoEl.srcObject = stream;
                
                // Wait for video to actually play before attaching AI
                videoEl.onloadedmetadata = () => {
                    videoEl.play();
                    startAIDetection();
                };
            } catch (err) {
                showError("Camera denied.");
            }
        }

        async function startAIDetection() {
            statusEl.innerText = "Looking for a face...";
            statusEl.className = "scanning";

            // Create a canvas to draw the detection box
            const canvas = faceapi.createCanvasFromMedia(videoEl);
            cameraWrapper.append(canvas);
            
            // Match canvas size to video size
            const displaySize = { width: videoEl.clientWidth, height: videoEl.clientHeight };
            faceapi.matchDimensions(canvas, displaySize);

            // Loop every 100ms
            detectionInterval = setInterval(async () => {
                // DETECT FACES using TinyFaceDetector
                const detections = await faceapi.detectAllFaces(videoEl, new faceapi.TinyFaceDetectorOptions());
                
                // Resize results to match display
                const resizedDetections = faceapi.resizeResults(detections, displaySize);
                
                // Clear previous drawings
                canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
                
                // DRAW THE BOX
                faceapi.draw.drawDetections(canvas, resizedDetections);

                if (detections.length > 0) {
                    faceConfirmedFrames++;
                    statusEl.innerText = `Face Detected... Hold still (${faceConfirmedFrames}/20)`;
                    
                    // If we see a face for ~2 seconds (20 frames)
                    if (faceConfirmedFrames > 20) {
                        finishAttendance();
                    }
                } else {
                    faceConfirmedFrames = 0; // Reset if face is lost
                    statusEl.innerText = "No face detected. Look at camera.";
                }
            }, 100);
        }

        function finishAttendance() {
            clearInterval(detectionInterval);
            statusEl.innerText = "‚úÖ ATTENDANCE MARKED!";
            statusEl.className = "success";
            
            // Draw a final "Success" message on canvas
            // Stop Video
            videoEl.srcObject.getTracks().forEach(track => track.stop());
        }

        // Ray Casting Algorithm for Geofence
        function isPointInPolygon(p, polygon) {
            let inside = false;
            for (let i = 0, j = polygon.length - 1; i < polygon.length; j = i++) {
                let xi = polygon[i].lat, yi = polygon[i].lng;
                let xj = polygon[j].lat, yj = polygon[j].lng;
                let intersect = ((yi > p.lng) != (yj > p.lng)) &&
                    (p.lat < (xj - xi) * (p.lng - yi) / (yj - yi) + xi);
                if (intersect) inside = !inside;
            }
            return inside;
        }

        function showError(msg) {
            statusEl.innerText = msg;
            statusEl.className = "error";
        }
    </script>
</body>
</html>